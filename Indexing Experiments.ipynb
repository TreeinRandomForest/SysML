{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c8ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03076970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367e3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc0323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(N=100, d=10, low=0, high=10, target_idx=3):\n",
    "    data = np.random.randint(low=low, high=high, size=(N,d))\n",
    "    return data, data[:, target_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592a6c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "train_data, train_target = gen_data(N=N)\n",
    "test_data, test_target = gen_data(N=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22daa5b",
   "metadata": {},
   "source": [
    "Input array: a\n",
    "\n",
    "Fixed index: i\n",
    "\n",
    "Experiment 1: Always predict entry in fixed index position: a $\\rightarrow$ a[i] #current PC\n",
    "\n",
    "Experiment 1a: Experiment 1 with i as an input\n",
    "\n",
    "Experiment 2: a $\\rightarrow$ a[target_idx + a[i]] #going to correct instruction location - offset\n",
    "\n",
    "Experiment 3: conditional on a[target_idx + a[i]] #increment to next PC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9076d0c",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "91be6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 10 #length of generated arrays\n",
    "low = 0 #values in array, v satisfy low <= v <= high-1 \n",
    "high = 10 #values in array, v satisfy low <= v <= high-1\n",
    "n_hidden = 10 #if net is MLP, number of hidden nodes (with 1 hidden layer)\n",
    "target_idx = 3 #target is array[target_idx]\n",
    "\n",
    "net = nn.Sequential(nn.Linear(d, n_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_hidden, high-low))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d495c65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.from_numpy(train_data[0:5]).float()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cf90918f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=2.937025308609009 train_acc = 0.101 test_acc = 0.109 train_rmse = 3.154  test_rmse = 3.090\n",
      "Epoch = 10 loss=2.3081398010253906 train_acc = 0.146 test_acc = 0.142 train_rmse = 3.994  test_rmse = 4.000\n",
      "Epoch = 20 loss=2.0940351486206055 train_acc = 0.229 test_acc = 0.226 train_rmse = 2.645  test_rmse = 2.597\n",
      "Epoch = 30 loss=1.821569561958313 train_acc = 0.275 test_acc = 0.268 train_rmse = 1.745  test_rmse = 1.748\n",
      "Epoch = 40 loss=1.6072783470153809 train_acc = 0.367 test_acc = 0.359 train_rmse = 1.218  test_rmse = 1.214\n",
      "Epoch = 50 loss=1.445681095123291 train_acc = 0.434 test_acc = 0.437 train_rmse = 1.049  test_rmse = 1.045\n",
      "Epoch = 60 loss=1.3340387344360352 train_acc = 0.503 test_acc = 0.507 train_rmse = 0.964  test_rmse = 0.953\n",
      "Epoch = 70 loss=1.2497198581695557 train_acc = 0.552 test_acc = 0.539 train_rmse = 0.937  test_rmse = 0.936\n",
      "Epoch = 80 loss=1.1837598085403442 train_acc = 0.590 test_acc = 0.573 train_rmse = 0.901  test_rmse = 0.900\n",
      "Epoch = 90 loss=1.1292152404785156 train_acc = 0.613 test_acc = 0.594 train_rmse = 0.868  test_rmse = 0.869\n",
      "Epoch = 100 loss=1.0822421312332153 train_acc = 0.628 test_acc = 0.607 train_rmse = 0.837  test_rmse = 0.840\n",
      "Epoch = 110 loss=1.0409425497055054 train_acc = 0.638 test_acc = 0.620 train_rmse = 0.811  test_rmse = 0.823\n",
      "Epoch = 120 loss=1.003950834274292 train_acc = 0.647 test_acc = 0.629 train_rmse = 0.790  test_rmse = 0.802\n",
      "Epoch = 130 loss=0.970352828502655 train_acc = 0.657 test_acc = 0.641 train_rmse = 0.768  test_rmse = 0.773\n",
      "Epoch = 140 loss=0.9391481280326843 train_acc = 0.663 test_acc = 0.647 train_rmse = 0.749  test_rmse = 0.756\n",
      "Epoch = 150 loss=0.9098504185676575 train_acc = 0.671 test_acc = 0.656 train_rmse = 0.721  test_rmse = 0.725\n",
      "Epoch = 160 loss=0.8818556666374207 train_acc = 0.679 test_acc = 0.666 train_rmse = 0.697  test_rmse = 0.705\n",
      "Epoch = 170 loss=0.8550907969474792 train_acc = 0.689 test_acc = 0.676 train_rmse = 0.677  test_rmse = 0.678\n",
      "Epoch = 180 loss=0.8289285898208618 train_acc = 0.702 test_acc = 0.686 train_rmse = 0.652  test_rmse = 0.658\n",
      "Epoch = 190 loss=0.8031404614448547 train_acc = 0.713 test_acc = 0.701 train_rmse = 0.624  test_rmse = 0.628\n",
      "Epoch = 200 loss=0.777305006980896 train_acc = 0.724 test_acc = 0.708 train_rmse = 0.603  test_rmse = 0.610\n",
      "Epoch = 210 loss=0.7502812743186951 train_acc = 0.737 test_acc = 0.721 train_rmse = 0.572  test_rmse = 0.576\n",
      "Epoch = 220 loss=0.7240011692047119 train_acc = 0.756 test_acc = 0.736 train_rmse = 0.538  test_rmse = 0.547\n",
      "Epoch = 230 loss=0.6980360746383667 train_acc = 0.767 test_acc = 0.751 train_rmse = 0.517  test_rmse = 0.526\n",
      "Epoch = 240 loss=0.6723964214324951 train_acc = 0.787 test_acc = 0.769 train_rmse = 0.486  test_rmse = 0.498\n",
      "Epoch = 250 loss=0.6467492580413818 train_acc = 0.796 test_acc = 0.777 train_rmse = 0.468  test_rmse = 0.482\n",
      "Epoch = 260 loss=0.6207851767539978 train_acc = 0.820 test_acc = 0.802 train_rmse = 0.436  test_rmse = 0.453\n",
      "Epoch = 270 loss=0.5980399250984192 train_acc = 0.843 test_acc = 0.824 train_rmse = 0.406  test_rmse = 0.425\n",
      "Epoch = 280 loss=0.5720627903938293 train_acc = 0.856 test_acc = 0.841 train_rmse = 0.384  test_rmse = 0.402\n",
      "Epoch = 290 loss=0.548036515712738 train_acc = 0.874 test_acc = 0.862 train_rmse = 0.359  test_rmse = 0.374\n",
      "Epoch = 300 loss=0.5247738361358643 train_acc = 0.887 test_acc = 0.876 train_rmse = 0.339  test_rmse = 0.354\n",
      "Epoch = 310 loss=0.5030813217163086 train_acc = 0.906 test_acc = 0.902 train_rmse = 0.311  test_rmse = 0.316\n",
      "Epoch = 320 loss=0.48104727268218994 train_acc = 0.920 test_acc = 0.922 train_rmse = 0.285  test_rmse = 0.279\n",
      "Epoch = 330 loss=0.46009546518325806 train_acc = 0.936 test_acc = 0.936 train_rmse = 0.254  test_rmse = 0.253\n",
      "Epoch = 340 loss=0.4401445686817169 train_acc = 0.950 test_acc = 0.947 train_rmse = 0.224  test_rmse = 0.231\n",
      "Epoch = 350 loss=0.42082923650741577 train_acc = 0.961 test_acc = 0.957 train_rmse = 0.197  test_rmse = 0.207\n",
      "Epoch = 360 loss=0.4062831401824951 train_acc = 0.966 test_acc = 0.962 train_rmse = 0.185  test_rmse = 0.194\n",
      "Epoch = 370 loss=0.3851070702075958 train_acc = 0.975 test_acc = 0.967 train_rmse = 0.159  test_rmse = 0.181\n",
      "Epoch = 380 loss=0.36774417757987976 train_acc = 0.981 test_acc = 0.975 train_rmse = 0.138  test_rmse = 0.157\n",
      "Epoch = 390 loss=0.3511003255844116 train_acc = 0.984 test_acc = 0.981 train_rmse = 0.126  test_rmse = 0.139\n",
      "Epoch = 400 loss=0.33560922741889954 train_acc = 0.986 test_acc = 0.984 train_rmse = 0.117  test_rmse = 0.126\n",
      "Epoch = 410 loss=0.32035279273986816 train_acc = 0.989 test_acc = 0.989 train_rmse = 0.103  test_rmse = 0.106\n",
      "Epoch = 420 loss=0.3057010769844055 train_acc = 0.992 test_acc = 0.991 train_rmse = 0.089  test_rmse = 0.095\n",
      "Epoch = 430 loss=0.2913714349269867 train_acc = 0.993 test_acc = 0.993 train_rmse = 0.082  test_rmse = 0.082\n",
      "Epoch = 440 loss=0.27815014123916626 train_acc = 0.995 test_acc = 0.995 train_rmse = 0.068  test_rmse = 0.069\n",
      "Epoch = 450 loss=0.26508623361587524 train_acc = 0.996 test_acc = 0.996 train_rmse = 0.063  test_rmse = 0.063\n",
      "Epoch = 460 loss=0.252591609954834 train_acc = 0.996 test_acc = 0.997 train_rmse = 0.062  test_rmse = 0.058\n",
      "Epoch = 470 loss=0.24227924644947052 train_acc = 0.997 test_acc = 0.997 train_rmse = 0.057  test_rmse = 0.053\n",
      "Epoch = 480 loss=0.230140820145607 train_acc = 0.997 test_acc = 0.997 train_rmse = 0.058  test_rmse = 0.057\n",
      "Epoch = 490 loss=0.21855182945728302 train_acc = 0.997 test_acc = 0.998 train_rmse = 0.051  test_rmse = 0.049\n",
      "Epoch = 500 loss=0.20801110565662384 train_acc = 0.998 test_acc = 0.998 train_rmse = 0.047  test_rmse = 0.047\n",
      "Epoch = 510 loss=0.19802077114582062 train_acc = 0.998 test_acc = 0.998 train_rmse = 0.047  test_rmse = 0.045\n",
      "Epoch = 520 loss=0.1885993480682373 train_acc = 0.998 test_acc = 0.999 train_rmse = 0.042  test_rmse = 0.035\n",
      "Epoch = 530 loss=0.1795722246170044 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.037  test_rmse = 0.035\n",
      "Epoch = 540 loss=0.1717371940612793 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.035  test_rmse = 0.032\n",
      "Epoch = 550 loss=0.1621628850698471 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.035  test_rmse = 0.032\n",
      "Epoch = 560 loss=0.15437592566013336 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.037  test_rmse = 0.032\n",
      "Epoch = 570 loss=0.14666737616062164 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.037  test_rmse = 0.032\n",
      "Epoch = 580 loss=0.1395021677017212 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.037  test_rmse = 0.028\n",
      "Epoch = 590 loss=0.13270923495292664 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.028  test_rmse = 0.024\n",
      "Epoch = 600 loss=0.1263340413570404 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.028  test_rmse = 0.024\n",
      "Epoch = 610 loss=0.12028807401657104 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.028  test_rmse = 0.024\n",
      "Epoch = 620 loss=0.11456899344921112 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.024  test_rmse = 0.024\n",
      "Epoch = 630 loss=0.1094379648566246 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.024\n",
      "Epoch = 640 loss=0.10411938279867172 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.024  test_rmse = 0.028\n",
      "Epoch = 650 loss=0.09923693537712097 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.024  test_rmse = 0.028\n",
      "Epoch = 660 loss=0.09474068880081177 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.024  test_rmse = 0.028\n",
      "Epoch = 670 loss=0.09059261530637741 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.024  test_rmse = 0.028\n",
      "Epoch = 680 loss=0.08654814213514328 train_acc = 0.999 test_acc = 0.999 train_rmse = 0.024  test_rmse = 0.028\n",
      "Epoch = 690 loss=0.08261197805404663 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 700 loss=0.07913987338542938 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 710 loss=0.08161961287260056 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 720 loss=0.07436308264732361 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 730 loss=0.07015783339738846 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 740 loss=0.06750401854515076 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 750 loss=0.06466330587863922 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 760 loss=0.06197325885295868 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 770 loss=0.059694647789001465 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 780 loss=0.05941552668809891 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 790 loss=0.057518597692251205 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.024\n",
      "Epoch = 800 loss=0.05422951653599739 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 810 loss=0.05231768265366554 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n",
      "Epoch = 820 loss=0.050665102899074554 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.028\n",
      "Epoch = 830 loss=0.0488918237388134 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 840 loss=0.047099530696868896 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.028\n",
      "Epoch = 850 loss=0.04572710767388344 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.028\n",
      "Epoch = 860 loss=0.04420098289847374 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.028\n",
      "Epoch = 870 loss=0.04291915148496628 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.028\n",
      "Epoch = 880 loss=0.04126940295100212 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.028\n",
      "Epoch = 890 loss=0.03976451978087425 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.028\n",
      "Epoch = 900 loss=0.038608066737651825 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.028\n",
      "Epoch = 910 loss=0.03737329691648483 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.024\n",
      "Epoch = 920 loss=0.03621530905365944 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.024\n",
      "Epoch = 930 loss=0.03537455573678017 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.024\n",
      "Epoch = 940 loss=0.034270770847797394 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.024\n",
      "Epoch = 950 loss=0.033201564103364944 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.024\n",
      "Epoch = 960 loss=0.03247091919183731 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.024\n",
      "Epoch = 970 loss=0.03145327791571617 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.024\n",
      "Epoch = 980 loss=0.030565716326236725 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.024\n",
      "Epoch = 990 loss=0.02990369312465191 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.014  test_rmse = 0.024\n"
     ]
    }
   ],
   "source": [
    "N_epochs = 10000\n",
    "\n",
    "def validate(net, test_data, test_target, net_type=None):\n",
    "    net = net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_data_torch = torch.from_numpy(test_data).float().to(device)\n",
    "        test_target_torch = torch.from_numpy(test_target).float().to(device)\n",
    "\n",
    "        if net_type=='conv':\n",
    "            test_data_torch = test_data_torch.unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        test_pred = net(test_data_torch).argmax(dim=1)\n",
    "        test_accuracy = (test_target_torch == test_pred).float().mean().to('cpu').detach().numpy()\n",
    "\n",
    "        test_rmse = ((test_pred-test_target_torch)**2).mean().sqrt().to('cpu').detach().numpy()\n",
    "\n",
    "    return test_accuracy, test_rmse\n",
    "\n",
    "def train_net(net, train_data, train_target, test_data, test_target, N_epochs=10, print_freq=100, net_type=None):\n",
    "    net = net.to(device)\n",
    "    train_data_torch = torch.from_numpy(train_data).float().to(device)\n",
    "    train_target_torch = torch.from_numpy(train_target).to(device)\n",
    "    \n",
    "    if net_type=='conv':\n",
    "        train_data_torch = train_data_torch.unsqueeze(1).unsqueeze(2)\n",
    "    \n",
    "    net = net.train()\n",
    "    for i in range(N_epochs):\n",
    "        pred = net(train_data_torch)\n",
    "        loss = criterion(pred, train_target_torch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            train_accuracy, train_rmse = validate(net, train_data, train_target, net_type=net_type)\n",
    "            test_accuracy, test_rmse = validate(net, test_data, test_target, net_type=net_type)\n",
    "            net = net.train()\n",
    "            print(f'Epoch = {i} loss={loss} train_acc = {train_accuracy:.3f} test_acc = {test_accuracy:.3f} train_rmse = {train_rmse:.3f}  test_rmse = {test_rmse:.3f}')\n",
    "            \n",
    "    return net\n",
    "\n",
    "net = train_net(net, train_data, train_target, test_data, test_target, N_epochs=1000, print_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e365d390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "tensor([-0.3015,  0.1111,  0.2111, -0.3045, -0.2890,  0.0473, -0.1259, -0.2070,\n",
      "        -0.2045, -0.3144], grad_fn=<SelectBackward0>)\n",
      "tensor(6.4355, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.0667, -0.1944,  0.0216,  0.1067,  0.1495, -0.0623,  0.2018, -0.1545,\n",
      "        -0.0649, -0.3151], grad_fn=<SelectBackward0>)\n",
      "tensor(4.9419, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.1088,  0.2854, -0.2113,  0.0557, -0.1331,  0.2542, -0.0837,  0.1790,\n",
      "         0.3101,  0.0939], grad_fn=<SelectBackward0>)\n",
      "tensor(1., grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.0322,  0.2941,  0.1110, -0.1791,  0.2127,  0.1184, -0.1106,  0.2899,\n",
      "         0.2439,  0.0996], grad_fn=<SelectBackward0>)\n",
      "tensor(5.5586, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.3080, -0.1598, -0.3045, -0.2603,  0.1060, -0.0187,  0.2244, -0.0984,\n",
      "         0.1602,  0.2788], grad_fn=<SelectBackward0>)\n",
      "tensor(13.8863, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.0815,  0.1844, -0.1693,  0.0600, -0.2865,  0.0814, -0.0856,  0.0808,\n",
      "        -0.2522, -0.0682], grad_fn=<SelectBackward0>)\n",
      "tensor(1., grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.1739,  0.0727, -0.2421, -0.2050, -0.0975,  0.0063,  0.1216,  0.2473,\n",
      "        -0.0782,  0.2024], grad_fn=<SelectBackward0>)\n",
      "tensor(32.7561, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.1377, -0.2286, -0.1070, -0.1348,  0.1392, -0.2988, -0.1628,  0.1888,\n",
      "        -0.1279, -0.0040], grad_fn=<SelectBackward0>)\n",
      "tensor(33.4646, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.1379, -0.2634, -0.0251, -0.1933,  0.2454,  0.1605,  0.1827,  0.1709,\n",
      "        -0.2573,  0.1363], grad_fn=<SelectBackward0>)\n",
      "tensor(7.7072, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.2298,  0.2194,  0.2526,  0.2857, -0.2314,  0.0255,  0.2487, -0.3092,\n",
      "        -0.1147, -0.1696], grad_fn=<SelectBackward0>)\n",
      "tensor(11.2022, grad_fn=<DivBackward0>)\n",
      "***\n",
      "---\n",
      "tensor([ 0.2258,  0.1332,  0.1845, -0.0225,  0.0876,  0.1157,  0.1256,  0.3101,\n",
      "         0.0139,  0.2178], grad_fn=<SelectBackward0>)\n",
      "tensor(1.6165, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.2833,  0.2926,  0.0577,  0.0035,  0.0979, -0.2058, -0.2654, -0.1208,\n",
      "        -0.2551,  0.1455], grad_fn=<SelectBackward0>)\n",
      "tensor(1., grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.0358, -0.2622,  0.2807,  0.1932,  0.1064, -0.2104,  0.0682, -0.0043,\n",
      "        -0.1205,  0.2960], grad_fn=<SelectBackward0>)\n",
      "tensor(44.8814, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.0828, -0.1732, -0.3119, -0.2885, -0.1266,  0.2837,  0.1576,  0.2909,\n",
      "         0.1675,  0.2851], grad_fn=<SelectBackward0>)\n",
      "tensor(3.4847, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.0125,  0.2397,  0.2675,  0.1460,  0.0427,  0.1122, -0.0882,  0.0599,\n",
      "        -0.0665, -0.1955], grad_fn=<SelectBackward0>)\n",
      "tensor(11.7094, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.2351, -0.3052, -0.2310, -0.2881,  0.2485, -0.2508,  0.0875, -0.1961,\n",
      "         0.2491, -0.1678], grad_fn=<SelectBackward0>)\n",
      "tensor(3.2922, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.2933, -0.1914, -0.1707, -0.2006,  0.2393,  0.1813,  0.0645,  0.1819,\n",
      "        -0.1888, -0.1735], grad_fn=<SelectBackward0>)\n",
      "tensor(3.1111, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.0458, -0.1909, -0.1748,  0.0249,  0.2560,  0.1510,  0.1812, -0.1467,\n",
      "        -0.1101, -0.2690], grad_fn=<SelectBackward0>)\n",
      "tensor(1., grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.0673,  0.2372,  0.2988,  0.0192,  0.0580, -0.2892, -0.2260,  0.0160,\n",
      "         0.3095, -0.1047], grad_fn=<SelectBackward0>)\n",
      "tensor(1.1999, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.1253,  0.2787,  0.2673, -0.0353,  0.2553,  0.2639, -0.2399, -0.1175,\n",
      "        -0.2720,  0.2835], grad_fn=<SelectBackward0>)\n",
      "tensor(1., grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#weights are not \"peaky\"\n",
    "\n",
    "for _ in range(n_hidden):\n",
    "    l = list(net.parameters())[0][_]\n",
    "    \n",
    "    print('---')\n",
    "    print(l)\n",
    "    print(l[target_idx].abs() / l.abs().min())\n",
    "    \n",
    "print('***')\n",
    "for _ in range(high-low):\n",
    "    l = list(net.parameters())[2][_]\n",
    "    \n",
    "    print('---')\n",
    "    print(l)\n",
    "    \n",
    "    print(l[target_idx].abs() / l.abs().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "80696b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1752,  0.3209, -0.4630, -0.7688, -0.1848,  0.3138,  0.4108,  0.3876,\n",
       "        -0.3857, -0.0603], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())[0].sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f2c8e597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3773, -0.2450,  0.8590,  1.0475,  0.2358, -0.3738,  0.2014, -0.5981,\n",
       "         0.0190, -0.0229], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())[0].sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2a6ba06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8., 17.,  9., 17.,  4., 15., 11., 17.,  7., 12.], device='cuda:0')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_torch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "761ba92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.469349  ,  0.64563804,  3.7054089 ,  4.40810317,  2.95738274,\n",
       "       -0.04907821,  2.83234672, -1.58928016,  0.44751332,  0.03399417])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np.array(list(net.parameters())[0].cpu().detach()), test_data[2]) + np.array(list(net.parameters())[1].cpu().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675fb492",
   "metadata": {},
   "source": [
    "### Experiments 1X:\n",
    "\n",
    "1a. what happens when number of hidden nodes is decreased from 20?\n",
    "\n",
    "1b. 2d (t-sne) visualizations\n",
    "\n",
    "    raw data -> t-sne (colors are the target value)\n",
    "    \n",
    "    raw data -> nn -> take the activations (20 intermediate values) -> t-sne (colors are the target value)\n",
    "    \n",
    "1c. interpreting nns: which input element has the most effect on the output\n",
    "\n",
    "1d. paths from each input node to each output node\n",
    "\n",
    "1e. compute derivatives of output nodes w.r.t. input nodes and look at max absolute value\n",
    "\n",
    "1f. replace net by convolutional net and check weights\n",
    "\n",
    "1g. try more hidden layers\n",
    "\n",
    "1h. try attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047eabaf",
   "metadata": {},
   "source": [
    "### Experiment 1a: vary n_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cb57a7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=2.6532723903656006 train_acc = 0.103 test_acc = 0.091 train_rmse = 3.908  test_rmse = 3.926\n",
      "Epoch = 1000 loss=1.1496717929840088 train_acc = 0.611 test_acc = 0.605 train_rmse = 0.984  test_rmse = 1.000\n",
      "Epoch = 2000 loss=0.8222751021385193 train_acc = 0.799 test_acc = 0.789 train_rmse = 0.713  test_rmse = 0.726\n",
      "Epoch = 3000 loss=0.6934895515441895 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 4000 loss=0.6076760292053223 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 5000 loss=0.5427573919296265 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 6000 loss=0.4914427101612091 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 7000 loss=0.45086073875427246 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 8000 loss=0.41952523589134216 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 9000 loss=0.3960285186767578 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 1\n",
    "\n",
    "net = nn.Sequential(nn.Linear(d, n_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_hidden, high-low))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "net = train_net(net, train_data, train_target, test_data, test_target, N_epochs=10000, print_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1bb8a71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=2.644395112991333 train_acc = 0.105 test_acc = 0.091 train_rmse = 3.576  test_rmse = 3.651\n",
      "Epoch = 1000 loss=0.990158200263977 train_acc = 0.703 test_acc = 0.701 train_rmse = 0.778  test_rmse = 0.784\n",
      "Epoch = 2000 loss=0.7899806499481201 train_acc = 0.803 test_acc = 0.793 train_rmse = 0.710  test_rmse = 0.721\n",
      "Epoch = 3000 loss=0.6769148707389832 train_acc = 0.803 test_acc = 0.794 train_rmse = 0.710  test_rmse = 0.721\n",
      "Epoch = 4000 loss=0.5960864424705505 train_acc = 0.803 test_acc = 0.793 train_rmse = 0.710  test_rmse = 0.723\n",
      "Epoch = 5000 loss=0.5335060358047485 train_acc = 0.803 test_acc = 0.793 train_rmse = 0.710  test_rmse = 0.723\n",
      "Epoch = 6000 loss=0.4838044345378876 train_acc = 0.803 test_acc = 0.793 train_rmse = 0.710  test_rmse = 0.723\n",
      "Epoch = 7000 loss=0.4445449113845825 train_acc = 0.803 test_acc = 0.793 train_rmse = 0.710  test_rmse = 0.723\n",
      "Epoch = 8000 loss=0.41438260674476624 train_acc = 0.803 test_acc = 0.793 train_rmse = 0.710  test_rmse = 0.723\n",
      "Epoch = 9000 loss=0.3918471336364746 train_acc = 0.803 test_acc = 0.793 train_rmse = 0.710  test_rmse = 0.723\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 2\n",
    "\n",
    "net = nn.Sequential(nn.Linear(d, n_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_hidden, high-low))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "net = train_net(net, train_data, train_target, test_data, test_target, N_epochs=10000, print_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f4572f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=2.5127551555633545 train_acc = 0.064 test_acc = 0.062 train_rmse = 4.560  test_rmse = 4.553\n",
      "Epoch = 1000 loss=1.1365019083023071 train_acc = 0.611 test_acc = 0.605 train_rmse = 0.834  test_rmse = 0.844\n",
      "Epoch = 2000 loss=0.7987487316131592 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 3000 loss=0.6724029779434204 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 4000 loss=0.5889480710029602 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 5000 loss=0.5264238715171814 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 6000 loss=0.4775548279285431 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 7000 loss=0.43960732221603394 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 8000 loss=0.41086357831954956 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n",
      "Epoch = 9000 loss=0.3896052837371826 train_acc = 0.801 test_acc = 0.793 train_rmse = 0.711  test_rmse = 0.723\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 3\n",
    "\n",
    "net = nn.Sequential(nn.Linear(d, n_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_hidden, high-low))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "net = train_net(net, train_data, train_target, test_data, test_target, N_epochs=10000, print_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "21ba19b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=2.3994696140289307 train_acc = 0.097 test_acc = 0.103 train_rmse = 5.352  test_rmse = 5.375\n",
      "Epoch = 1000 loss=0.16526924073696136 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 2000 loss=0.03721220791339874 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3000 loss=0.014808270148932934 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4000 loss=0.007174258586019278 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 5000 loss=0.0038195305969566107 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 6000 loss=0.002136622089892626 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 7000 loss=0.0012317924993112683 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 8000 loss=0.0007227032911032438 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 9000 loss=0.0004288126074243337 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 4\n",
    "\n",
    "net = nn.Sequential(nn.Linear(d, n_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_hidden, high-low))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "net = train_net(net, train_data, train_target, test_data, test_target, N_epochs=10000, print_freq=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abae7ac",
   "metadata": {},
   "source": [
    "### Question for experiment 1a: why is n_hidden=4 where a sudden transition in performance takes place? Is it related to target_idx=3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8ca39bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "train_data, train_target = gen_data(N=N, target_idx=6)\n",
    "test_data, test_target = gen_data(N=N, target_idx=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c471a517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=2.772714376449585 train_acc = 0.095 test_acc = 0.091 train_rmse = 4.494  test_rmse = 4.515\n",
      "Epoch = 1000 loss=2.301755905151367 train_acc = 0.106 test_acc = 0.096 train_rmse = 4.540  test_rmse = 4.522\n",
      "Epoch = 2000 loss=2.301205635070801 train_acc = 0.107 test_acc = 0.096 train_rmse = 4.536  test_rmse = 4.517\n",
      "Epoch = 3000 loss=2.2999746799468994 train_acc = 0.107 test_acc = 0.097 train_rmse = 4.520  test_rmse = 4.502\n",
      "Epoch = 4000 loss=0.8183386325836182 train_acc = 0.796 test_acc = 0.781 train_rmse = 0.452  test_rmse = 0.468\n",
      "Epoch = 5000 loss=0.6665934324264526 train_acc = 0.809 test_acc = 0.794 train_rmse = 0.437  test_rmse = 0.454\n",
      "Epoch = 6000 loss=0.5768826007843018 train_acc = 0.809 test_acc = 0.794 train_rmse = 0.437  test_rmse = 0.454\n",
      "Epoch = 7000 loss=0.5124085545539856 train_acc = 0.809 test_acc = 0.794 train_rmse = 0.437  test_rmse = 0.454\n",
      "Epoch = 8000 loss=0.46353697776794434 train_acc = 0.809 test_acc = 0.794 train_rmse = 0.437  test_rmse = 0.454\n",
      "Epoch = 9000 loss=0.4264775514602661 train_acc = 0.809 test_acc = 0.794 train_rmse = 0.437  test_rmse = 0.454\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 1\n",
    "\n",
    "net = nn.Sequential(nn.Linear(d, n_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_hidden, high-low))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "net = train_net(net, train_data, train_target, test_data, test_target, N_epochs=10000, print_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3267b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=3.048898696899414 train_acc = 0.104 test_acc = 0.119 train_rmse = 3.477  test_rmse = 3.484\n",
      "Epoch = 1000 loss=1.1101036071777344 train_acc = 0.609 test_acc = 0.584 train_rmse = 0.837  test_rmse = 0.846\n",
      "Epoch = 2000 loss=0.4700790047645569 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3000 loss=0.23210586607456207 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4000 loss=0.1511794626712799 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 5000 loss=0.10203485190868378 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 6000 loss=0.06872177869081497 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 7000 loss=0.04601314291357994 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 8000 loss=0.030869195237755775 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 9000 loss=0.020733289420604706 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 2\n",
    "\n",
    "net = nn.Sequential(nn.Linear(d, n_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_hidden, high-low))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "net = train_net(net, train_data, train_target, test_data, test_target, N_epochs=10000, print_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e9e6cb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=2.9217448234558105 train_acc = 0.126 test_acc = 0.116 train_rmse = 4.126  test_rmse = 4.136\n",
      "Epoch = 1000 loss=0.12990738451480865 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.060  test_rmse = 0.014\n",
      "Epoch = 2000 loss=0.017265046015381813 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.014\n",
      "Epoch = 3000 loss=0.005189168732613325 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4000 loss=0.0021064416505396366 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 5000 loss=0.0009787054732441902 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 6000 loss=0.0004875070007983595 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 7000 loss=0.00025403936160728335 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 8000 loss=0.0001347991346847266 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 9000 loss=7.23699267837219e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 3\n",
    "\n",
    "net = nn.Sequential(nn.Linear(d, n_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_hidden, high-low))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "net = train_net(net, train_data, train_target, test_data, test_target, N_epochs=10000, print_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "65667f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=2.7339725494384766 train_acc = 0.119 test_acc = 0.110 train_rmse = 4.634  test_rmse = 4.647\n",
      "Epoch = 1000 loss=0.14368084073066711 train_acc = 0.999 test_acc = 1.000 train_rmse = 0.028  test_rmse = 0.000\n",
      "Epoch = 2000 loss=0.01617692969739437 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.014  test_rmse = 0.000\n",
      "Epoch = 3000 loss=0.004698417615145445 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4000 loss=0.0018843208672478795 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 5000 loss=0.0008788132690824568 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 6000 loss=0.0004434954607859254 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 7000 loss=0.00023419401259161532 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 8000 loss=0.00012716562196146697 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 9000 loss=7.030292908893898e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 4\n",
    "\n",
    "net = nn.Sequential(nn.Linear(d, n_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_hidden, high-low))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "net = train_net(net, train_data, train_target, test_data, test_target, N_epochs=10000, print_freq=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d1b99",
   "metadata": {},
   "source": [
    "### Note: When target_idx was changed to 6, even n_hidden=2 worked well (in terms of performance on test set). Why?\n",
    "\n",
    "Plot 1: Plot input vectors\n",
    "* Input vectors are 10d\n",
    "* Use t-sne to map it to 2d and plot. Color each point by the target value\n",
    "\n",
    "Plot 2: Plot hidden activations (n_hidden=2 or n_hidden=3)\n",
    "* Plot hidden layer activations for each input vector and color them by the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b7c87530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=3.2268967628479004 train_acc = 0.108 test_acc = 0.103 train_rmse = 4.337  test_rmse = 4.337\n",
      "Epoch = 1000 loss=1.109921932220459 train_acc = 0.609 test_acc = 0.587 train_rmse = 0.836  test_rmse = 0.844\n",
      "Epoch = 2000 loss=0.9139060378074646 train_acc = 0.706 test_acc = 0.694 train_rmse = 0.776  test_rmse = 0.777\n",
      "Epoch = 3000 loss=0.2796461880207062 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4000 loss=0.16456685960292816 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 5000 loss=0.11058631539344788 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 6000 loss=0.07540344446897507 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 7000 loss=0.051220472902059555 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 8000 loss=0.03460615873336792 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 9000 loss=0.0234210304915905 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 2\n",
    "\n",
    "net = nn.Sequential(nn.Linear(d, n_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_hidden, high-low))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "net = train_net(net, train_data, train_target, test_data, test_target, N_epochs=10000, print_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2cc93d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 142.4816,  138.6892,  127.0850,  105.7965,   71.8712,   13.4982,\n",
       "        -754.4501, -165.0163, -167.9870, -192.0000], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.from_numpy(train_data[0]).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b4b39977",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "act = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b80e1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_act = torch.matmul(params[0], torch.from_numpy(train_data[0]).float().to(device)) + params[1]\n",
    "\n",
    "layer1_act_relu = act(layer1_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "6f3c8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_act = torch.matmul(params[2], layer1_act_relu) + params[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "12182f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 142.4816,  138.6892,  127.0850,  105.7965,   71.8712,   13.4982,\n",
       "        -754.4501, -165.0163, -167.9870, -192.0000], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3a691bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 18.6105, -14.9387], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "97cc5049",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_act = torch.matmul(torch.from_numpy(train_data).float().to(device), params[0].T) + params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "40a57d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_act = layer1_act.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "633972af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f63a3682e80>]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(layer1_act[:,0], layer1_act[:,1], 'p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634c03f",
   "metadata": {},
   "source": [
    "#### Experiment 1g: Convolutional net for indexing: a -> a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a87cad95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=2.310180187225342 train_acc = 0.134 test_acc = 0.129 train_rmse = 4.250  test_rmse = 4.230\n",
      "Epoch = 10 loss=1.6137149333953857 train_acc = 0.348 test_acc = 0.325 train_rmse = 1.403  test_rmse = 1.440\n",
      "Epoch = 20 loss=1.2371515035629272 train_acc = 0.418 test_acc = 0.403 train_rmse = 1.006  test_rmse = 1.010\n",
      "Epoch = 30 loss=1.0202583074569702 train_acc = 0.578 test_acc = 0.554 train_rmse = 0.785  test_rmse = 0.809\n",
      "Epoch = 40 loss=0.891410231590271 train_acc = 0.630 test_acc = 0.614 train_rmse = 0.770  test_rmse = 0.781\n",
      "Epoch = 50 loss=0.8740519285202026 train_acc = 0.663 test_acc = 0.640 train_rmse = 0.622  test_rmse = 0.638\n",
      "Epoch = 60 loss=0.6517972946166992 train_acc = 0.756 test_acc = 0.734 train_rmse = 0.505  test_rmse = 0.525\n",
      "Epoch = 70 loss=0.499099463224411 train_acc = 0.877 test_acc = 0.857 train_rmse = 0.351  test_rmse = 0.378\n",
      "Epoch = 80 loss=0.5972312092781067 train_acc = 0.678 test_acc = 0.662 train_rmse = 0.653  test_rmse = 0.681\n",
      "Epoch = 90 loss=0.47381529211997986 train_acc = 0.883 test_acc = 0.867 train_rmse = 0.344  test_rmse = 0.366\n",
      "Epoch = 100 loss=0.36988505721092224 train_acc = 0.960 test_acc = 0.957 train_rmse = 0.201  test_rmse = 0.207\n",
      "Epoch = 110 loss=0.28781983256340027 train_acc = 0.982 test_acc = 0.979 train_rmse = 0.133  test_rmse = 0.145\n",
      "Epoch = 120 loss=0.3503682613372803 train_acc = 0.781 test_acc = 0.785 train_rmse = 0.468  test_rmse = 0.463\n",
      "Epoch = 130 loss=0.3678218126296997 train_acc = 0.981 test_acc = 0.980 train_rmse = 0.138  test_rmse = 0.143\n",
      "Epoch = 140 loss=0.2060212343931198 train_acc = 0.973 test_acc = 0.968 train_rmse = 0.165  test_rmse = 0.180\n",
      "Epoch = 150 loss=0.2369438260793686 train_acc = 0.998 test_acc = 0.998 train_rmse = 0.042  test_rmse = 0.049\n",
      "Epoch = 160 loss=0.3131905198097229 train_acc = 0.858 test_acc = 0.860 train_rmse = 0.377  test_rmse = 0.374\n",
      "Epoch = 170 loss=0.19478948414325714 train_acc = 0.998 test_acc = 0.998 train_rmse = 0.047  test_rmse = 0.047\n",
      "Epoch = 180 loss=0.11633582413196564 train_acc = 0.997 test_acc = 0.995 train_rmse = 0.055  test_rmse = 0.069\n",
      "Epoch = 190 loss=0.09140723198652267 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.020  test_rmse = 0.028\n"
     ]
    }
   ],
   "source": [
    "d = 10 #length of generated arrays\n",
    "low = 0 #values in array, v satisfy low <= v <= high-1 \n",
    "high = 10 #values in array, v satisfy low <= v <= high-1\n",
    "n_hidden = 10 #if net is MLP, number of hidden nodes (with 1 hidden layer)\n",
    "target_idx = 3 #target is array[target_idx]\n",
    "\n",
    "net = nn.Sequential(nn.Conv2d(1, 8, kernel_size=(1,3), stride=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(8, 16, kernel_size=(1,3), stride=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(16, 32, kernel_size=(1,3), stride=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "                    nn.Linear(128, high-low) #output layer: stays the same\n",
    "                   )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "net = train_net(net, train_data, train_target, test_data, test_target, N_epochs=200, print_freq=10, net_type='conv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cdfe24",
   "metadata": {},
   "source": [
    "##### Interpreting conv filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0d77b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_torch = torch.from_numpy(train_data).float()\n",
    "train_target_torch = torch.from_numpy(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f0d9544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-257.4438, -167.5562,  -96.5393,  -48.5901,  -15.3641,    4.1092,\n",
       "           15.8687,   25.2410,   28.5121,   26.6456]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(train_data_torch[[0]].unsqueeze(1).unsqueeze(2).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e7e21bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4551936 , -0.2917346 , -0.35919452],\n",
       "       [ 0.20683491,  0.3013565 ,  0.36513108],\n",
       "       [ 0.5832914 ,  0.15777262,  0.01081634],\n",
       "       [-0.31274712,  0.52892417, -0.25362423],\n",
       "       [-0.08488885, -0.03802393,  0.00662402],\n",
       "       [ 0.03717137,  0.62884265,  0.05331021],\n",
       "       [ 0.455009  ,  0.9706499 , -0.16476205],\n",
       "       [ 0.9354688 , -0.07806922,  0.00116902]], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(list(list(net.named_children())[0][1].parameters())[0].squeeze(1).squeeze(1).to('cpu').detach().numpy())\n",
    "list(list(net.named_children())[0][1].parameters())[0].squeeze(1).squeeze(1).to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "42ecd4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0e6586f220>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = train_data_torch[[0]].unsqueeze(1).unsqueeze(2).to(device)\n",
    "img0 = x.squeeze(1).squeeze(2).squeeze(0).to('cpu').detach().numpy()\n",
    "plt.imshow(img0)\n",
    "\n",
    "plt.figure()\n",
    "x = list(net.named_children())[0][1](x)\n",
    "img1 = x.squeeze(1).squeeze(2).squeeze(0).to('cpu').detach().numpy()\n",
    "plt.imshow(img1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9db3a58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', Conv2d(1, 8, kernel_size=(1, 3), stride=(1, 1))),\n",
       " ('1', ReLU()),\n",
       " ('2', Conv2d(8, 16, kernel_size=(1, 3), stride=(1, 1))),\n",
       " ('3', ReLU()),\n",
       " ('4', Conv2d(16, 32, kernel_size=(1, 3), stride=(1, 1))),\n",
       " ('5', ReLU()),\n",
       " ('6', Flatten(start_dim=1, end_dim=-1)),\n",
       " ('7', Linear(in_features=128, out_features=10, bias=True))]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daabb16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
