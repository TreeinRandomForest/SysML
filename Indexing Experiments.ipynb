{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ea5c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d04d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "798ff78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5067f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(N=100, d=10, low=0, high=10, target_idx=3):\n",
    "    data = np.random.randint(low=low, high=high, size=(N,d))\n",
    "    return data, data[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bee7f30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 10,  8, 17,  0,  5, 12,  3, 19, 14])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2e1b6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "train_data, train_target = gen_data(N=N)\n",
    "test_data, test_target = gen_data(N=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c324a",
   "metadata": {},
   "source": [
    "Input array: a\n",
    "\n",
    "Fixed index: i\n",
    "\n",
    "Experiment 1: Always predict entry in fixed index position: a $\\rightarrow$ a[i] #current PC\n",
    "\n",
    "Experiment 2: a $\\rightarrow$ a[target_idx + a[i]] #going to correct instruction location - offset\n",
    "\n",
    "Experiment 3: conditional on a[target_idx + a[i]] #increment to next PC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78292ba0",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5f577c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 10\n",
    "low = 0\n",
    "high = 10\n",
    "n_hidden = 10\n",
    "target_idx = 3\n",
    "\n",
    "net = nn.Sequential(nn.Linear(d, n_hidden),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(n_hidden, high-low))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b03c22ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.from_numpy(train_data[0:5]).float()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f4431038",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss=3.0839340686798096 train_acc = 0.064 test_acc = 0.056 train_rmse = 5.120  test_rmse = 5.176\n",
      "Epoch = 100 loss=1.172898292541504 train_acc = 0.603 test_acc = 0.604 train_rmse = 0.850  test_rmse = 0.856\n",
      "Epoch = 200 loss=0.7593762278556824 train_acc = 0.745 test_acc = 0.746 train_rmse = 0.545  test_rmse = 0.542\n",
      "Epoch = 300 loss=0.47754454612731934 train_acc = 0.943 test_acc = 0.941 train_rmse = 0.240  test_rmse = 0.242\n",
      "Epoch = 400 loss=0.31051865220069885 train_acc = 0.992 test_acc = 0.991 train_rmse = 0.092  test_rmse = 0.093\n",
      "Epoch = 500 loss=0.20938293635845184 train_acc = 0.999 test_acc = 0.997 train_rmse = 0.042  test_rmse = 0.053\n",
      "Epoch = 600 loss=0.1411212533712387 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.000  test_rmse = 0.035\n",
      "Epoch = 700 loss=0.09734237939119339 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.000  test_rmse = 0.032\n",
      "Epoch = 800 loss=0.06903334707021713 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.000  test_rmse = 0.035\n",
      "Epoch = 900 loss=0.05051704868674278 train_acc = 1.000 test_acc = 0.999 train_rmse = 0.000  test_rmse = 0.024\n",
      "Epoch = 1000 loss=0.038105957210063934 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.014\n",
      "Epoch = 1100 loss=0.02950236201286316 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.014\n",
      "Epoch = 1200 loss=0.023372715339064598 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.014\n",
      "Epoch = 1300 loss=0.018870051950216293 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.014\n",
      "Epoch = 1400 loss=0.01543573010712862 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.014\n",
      "Epoch = 1500 loss=0.012806471437215805 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 1600 loss=0.010760107077658176 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 1700 loss=0.00913497805595398 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 1800 loss=0.007824989035725594 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 1900 loss=0.006758800707757473 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 2000 loss=0.00588690210133791 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 2100 loss=0.005165220703929663 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 2200 loss=0.004559998866170645 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 2300 loss=0.004048406612128019 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 2400 loss=0.0036106056068092585 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 2500 loss=0.0032330749090760946 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 2600 loss=0.002905503613874316 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 2700 loss=0.0026197463739663363 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 2800 loss=0.002369144232943654 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 2900 loss=0.002148411935195327 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3000 loss=0.001953152008354664 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3100 loss=0.001779724843800068 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3200 loss=0.0016251237830147147 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3300 loss=0.0014868623111397028 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3400 loss=0.0013628607848659158 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3500 loss=0.0012512936955317855 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3600 loss=0.0011506605660542846 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3700 loss=0.0010596869979053736 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3800 loss=0.0009772242046892643 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 3900 loss=0.0009023203165270388 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4000 loss=0.00083410699153319 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4100 loss=0.0007718865526840091 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4200 loss=0.0007150561432354152 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4300 loss=0.0006630067946389318 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4400 loss=0.0006152997957542539 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4500 loss=0.0005715461447834969 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4600 loss=0.0005313589936122298 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.000\n",
      "Epoch = 4700 loss=0.0004943992826156318 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 4800 loss=0.0004603845009114593 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 4900 loss=0.00042950137867592275 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 5000 loss=0.0004009281692560762 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 5100 loss=0.00037464144406840205 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 5200 loss=0.0003500719030853361 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 5300 loss=0.0003276674833614379 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 5400 loss=0.0003065277705900371 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 5500 loss=0.00028720631962642074 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 5600 loss=0.0002701790945138782 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 5700 loss=0.0002532247162889689 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 5800 loss=0.00023651363153476268 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 5900 loss=0.00022181181702762842 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 6000 loss=0.00020831449364777654 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 6100 loss=0.0001954421604750678 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 6200 loss=0.00018412699864711612 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 6300 loss=0.00017272558761760592 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 6400 loss=0.0001621874253032729 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 6500 loss=0.00015269307186827064 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 6600 loss=0.000143603581818752 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 6700 loss=0.00013501395005732775 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 6800 loss=0.0001270168722840026 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 6900 loss=0.00011964750592596829 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 7000 loss=0.00011249673116253689 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 7100 loss=0.0001057722547557205 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 7200 loss=0.00010007042874349281 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 7300 loss=9.38013254199177e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7400 loss=8.84419641806744e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 7500 loss=8.329381671501324e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 7600 loss=7.863183418521658e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 7700 loss=7.400791946565732e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 7800 loss=6.980789476074278e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 7900 loss=6.578118336619809e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 8000 loss=6.233590102056041e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 8100 loss=5.867405707249418e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 8200 loss=5.5152289860416204e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 8300 loss=5.2090257668169215e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 8400 loss=4.918468403047882e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 8500 loss=4.63728210888803e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 8600 loss=4.37655980931595e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 8700 loss=4.1363506170455366e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 8800 loss=3.900877709384076e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 8900 loss=3.6830180761171505e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 9000 loss=3.475409539532848e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 9100 loss=3.282679244875908e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 9200 loss=3.100457615801133e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 9300 loss=2.9289216399774887e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 9400 loss=2.7640702683129348e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 9500 loss=2.6107836674782448e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 9600 loss=2.4662933356012218e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 9700 loss=2.3310649339691736e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 9800 loss=2.2012167391949333e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n",
      "Epoch = 9900 loss=2.079188016068656e-05 train_acc = 1.000 test_acc = 1.000 train_rmse = 0.000  test_rmse = 0.028\n"
     ]
    }
   ],
   "source": [
    "net = net.to(device)\n",
    "N_epochs = 10000\n",
    "\n",
    "train_data_torch = torch.from_numpy(train_data).float().to(device)\n",
    "train_target_torch = torch.from_numpy(train_target).to(device)\n",
    "\n",
    "def validate(net, test_data, test_target):\n",
    "    \n",
    "    test_data_torch = torch.from_numpy(test_data).float().to(device)\n",
    "    test_target_torch = torch.from_numpy(test_target).float().to(device)\n",
    "\n",
    "    test_pred = net(test_data_torch).argmax(dim=1)\n",
    "    test_accuracy = (test_target_torch == test_pred).float().mean().to('cpu').detach().numpy()\n",
    "\n",
    "    test_rmse = ((test_pred-test_target_torch)**2).mean().sqrt().to('cpu').detach().numpy()\n",
    "\n",
    "    return test_accuracy, test_rmse\n",
    "\n",
    "for i in range(N_epochs):\n",
    "    pred = net(train_data_torch)\n",
    "    loss = criterion(pred, train_target_torch)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        train_accuracy, train_rmse = validate(net, train_data, train_target)\n",
    "        test_accuracy, test_rmse = validate(net, test_data, test_target)\n",
    "        print(f'Epoch = {i} loss={loss} train_acc = {train_accuracy:.3f} test_acc = {test_accuracy:.3f} train_rmse = {train_rmse:.3f}  test_rmse = {test_rmse:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f49a8f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "tensor([-0.0800, -0.1408, -0.1178, -0.2991,  0.1991, -0.1334, -0.2901, -0.2046,\n",
      "         0.0387, -0.1757], grad_fn=<SelectBackward0>)\n",
      "tensor(7.7322, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.2968,  0.2352, -0.1972, -0.1490,  0.0768, -0.0311,  0.0108,  0.1800,\n",
      "        -0.0566,  0.2452], grad_fn=<SelectBackward0>)\n",
      "tensor(13.7839, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.2986, -0.1014,  0.3023,  0.0371,  0.3115,  0.2062, -0.1687, -0.1000,\n",
      "        -0.3145, -0.2613], grad_fn=<SelectBackward0>)\n",
      "tensor(1., grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.2468,  0.2756, -0.2339, -0.2362,  0.2236, -0.0384, -0.0148,  0.2684,\n",
      "        -0.2050,  0.0962], grad_fn=<SelectBackward0>)\n",
      "tensor(15.9630, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.0620, -0.1065, -0.1631,  0.3001, -0.1489, -0.0319, -0.2194,  0.1046,\n",
      "        -0.0094,  0.2317], grad_fn=<SelectBackward0>)\n",
      "tensor(31.8040, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.0090,  0.2770, -0.2179, -0.2923, -0.0290, -0.3144,  0.0888, -0.1450,\n",
      "         0.2830, -0.2811], grad_fn=<SelectBackward0>)\n",
      "tensor(32.5388, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.1280, -0.1530, -0.2928, -0.3125,  0.3027,  0.2340, -0.0258, -0.0613,\n",
      "        -0.0373, -0.1755], grad_fn=<SelectBackward0>)\n",
      "tensor(12.1361, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.0959, -0.0771,  0.2875,  0.3109,  0.1504, -0.0525, -0.1222, -0.0984,\n",
      "        -0.2746,  0.2380], grad_fn=<SelectBackward0>)\n",
      "tensor(5.9189, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.2366, -0.0340, -0.0230,  0.2863, -0.2333, -0.2927, -0.0352, -0.0327,\n",
      "         0.2885,  0.2879], grad_fn=<SelectBackward0>)\n",
      "tensor(12.4462, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.1268,  0.0691, -0.1510,  0.1286,  0.1623, -0.1231, -0.1991,  0.0523,\n",
      "         0.0009,  0.0301], grad_fn=<SelectBackward0>)\n",
      "tensor(135.7578, grad_fn=<DivBackward0>)\n",
      "***\n",
      "---\n",
      "tensor([ 0.0984,  0.0863, -0.1821, -0.2890, -0.0634,  0.1457,  0.1170, -0.0894,\n",
      "         0.0575, -0.2317], grad_fn=<SelectBackward0>)\n",
      "tensor(5.0244, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.3032, -0.0326,  0.0355, -0.1878, -0.0442, -0.2354,  0.2951,  0.1973,\n",
      "         0.0674, -0.2821], grad_fn=<SelectBackward0>)\n",
      "tensor(5.7562, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.1682,  0.2694,  0.2165, -0.3128, -0.0121, -0.1835,  0.2889,  0.2921,\n",
      "        -0.0063,  0.2076], grad_fn=<SelectBackward0>)\n",
      "tensor(49.4391, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.0064, -0.1448,  0.3088,  0.2432, -0.0579,  0.0804, -0.2885, -0.2866,\n",
      "        -0.2454,  0.0329], grad_fn=<SelectBackward0>)\n",
      "tensor(37.8087, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.1600, -0.0292, -0.2653, -0.1933, -0.1472,  0.2616,  0.2461,  0.0119,\n",
      "        -0.0502, -0.1639], grad_fn=<SelectBackward0>)\n",
      "tensor(16.3146, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.0954, -0.2837,  0.0708, -0.1831,  0.1366, -0.1131,  0.1721,  0.3009,\n",
      "        -0.1860,  0.2884], grad_fn=<SelectBackward0>)\n",
      "tensor(2.5869, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.0334,  0.1928, -0.1532, -0.2216,  0.2633,  0.2556,  0.2383, -0.0513,\n",
      "        -0.0229,  0.1156], grad_fn=<SelectBackward0>)\n",
      "tensor(9.6884, grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.0284, -0.0714, -0.1690,  0.0080, -0.1924,  0.1602, -0.1090, -0.1757,\n",
      "         0.1024, -0.1219], grad_fn=<SelectBackward0>)\n",
      "tensor(1., grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([-0.2818,  0.2408, -0.1567,  0.0061,  0.1670,  0.1092,  0.3120, -0.3122,\n",
      "         0.1075,  0.1393], grad_fn=<SelectBackward0>)\n",
      "tensor(1., grad_fn=<DivBackward0>)\n",
      "---\n",
      "tensor([ 0.2054, -0.1444, -0.2564,  0.1300, -0.2613, -0.0118, -0.2651, -0.0813,\n",
      "        -0.2131,  0.1129], grad_fn=<SelectBackward0>)\n",
      "tensor(11.0513, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#weights are not \"peaky\"\n",
    "\n",
    "for _ in range(n_hidden):\n",
    "    l = list(net.parameters())[0][_]\n",
    "    \n",
    "    print('---')\n",
    "    print(l)\n",
    "    print(l[target_idx].abs() / l.abs().min())\n",
    "    \n",
    "print('***')\n",
    "for _ in range(high-low):\n",
    "    l = list(net.parameters())[2][_]\n",
    "    \n",
    "    print('---')\n",
    "    print(l)\n",
    "    \n",
    "    print(l[target_idx].abs() / l.abs().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "84cfbba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9449,  0.2442, -0.8069, -0.2262,  1.0153, -0.5774, -0.9757, -0.0368,\n",
       "        -0.2862,  0.2354], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())[0].sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "163d011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2038,  0.0172, -0.3875,  0.3824,  0.0191, -0.6219, -0.6494,  0.2659,\n",
       "        -0.0248, -0.1566], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())[0].sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eb65e7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8., 17.,  9., 17.,  4., 15., 11., 17.,  7., 12.], device='cuda:0')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_torch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2b20c8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.4826468 ,   2.28380267, -36.50725102,   6.21199597,\n",
       "         3.45775655, -16.23347923, 390.02531135,  16.91296743,\n",
       "       141.38191938,   2.78582338,  14.43411553,   2.15547779,\n",
       "       -29.41698521, -22.8365572 ,   3.5040608 , -21.2656742 ,\n",
       "       -35.28759741, -42.19878227, -17.10998713, -24.47549912])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np.array(list(net.parameters())[0].cpu().detach()), test_data[2]) + np.array(list(net.parameters())[1].cpu().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8cd43b",
   "metadata": {},
   "source": [
    "### Experiments 1X:\n",
    "\n",
    "1a. what happens when number of hidden nodes is decreased from 20?\n",
    "\n",
    "1b. 2d (t-sne) visualizations\n",
    "\n",
    "    raw data -> t-sne (colors are the target value)\n",
    "    \n",
    "    raw data -> nn -> take the activations (20 intermediate values) -> t-sne (colors are the target value)\n",
    "    \n",
    "1c. interpreting nns: which input element has the most effect on the output\n",
    "\n",
    "1d. paths from each input node to each output node\n",
    "\n",
    "1e. compute derivatives of output nodes w.r.t. input nodes and look at max absolute value\n",
    "\n",
    "1f. replace net by convolutional net and check weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75754e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
